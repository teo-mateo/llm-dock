<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Benchmark - LLM Dashboard</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <style>
        .terminal-output {
            font-family: 'Courier New', monospace;
            font-size: 0.85rem;
            line-height: 1.4;
            white-space: pre-wrap;
            word-break: break-all;
        }
        .toast {
            animation: slideIn 0.3s ease-out, fadeOut 0.3s ease-in 2.7s;
        }
        @keyframes slideIn {
            from { transform: translateY(-20px); opacity: 0; }
            to { transform: translateY(0); opacity: 1; }
        }
        @keyframes fadeOut {
            from { opacity: 1; }
            to { opacity: 0; }
        }
        .param-tooltip {
            position: absolute;
            left: 0;
            bottom: calc(100% + 6px);
            z-index: 50;
            width: 280px;
            background: #1e293b;
            border: 1px solid #475569;
            border-radius: 8px;
            padding: 10px 12px;
            font-size: 12px;
            line-height: 1.5;
            color: #cbd5e1;
            box-shadow: 0 4px 20px rgba(0,0,0,0.4);
            pointer-events: none;
            opacity: 0;
            transition: opacity 0.15s;
        }
        .param-tooltip::after {
            content: '';
            position: absolute;
            top: 100%;
            left: 16px;
            border: 6px solid transparent;
            border-top-color: #475569;
        }
        .param-ref-row:hover .param-tooltip {
            opacity: 1;
        }
    </style>
</head>
<body class="bg-gray-900 text-white min-h-screen">

<!-- Toast container -->
<div id="toast-container" class="fixed top-4 right-4 z-50 flex flex-col gap-2"></div>

<div class="max-w-7xl mx-auto p-6">

    <!-- Header -->
    <div class="mb-6">
        <a href="/" class="text-blue-400 hover:text-blue-300 text-sm mb-3 inline-block">
            <i class="fa-solid fa-arrow-left mr-1"></i> Back to Dashboard
        </a>
        <div class="flex items-center gap-3 mb-1">
            <h1 class="text-2xl font-bold">
                Benchmark: <span id="service-name" class="text-yellow-400">—</span>
            </h1>
            <span id="service-status-badge" class="px-2 py-0.5 rounded text-xs font-semibold bg-gray-700 text-gray-400">
                Unknown
            </span>
        </div>
        <p class="text-gray-400 text-sm">
            Model: <span id="model-path" class="text-gray-300 font-mono">—</span>
        </p>
    </div>

    <!-- Two-column: Parameters (left) + Reference (right) -->
    <div class="flex flex-col lg:flex-row gap-4 mb-4">

        <!-- Left column: Parameters + Command Preview + Run -->
        <div id="left-column" class="flex-1 min-w-0">
            <!-- Parameters -->
            <div class="bg-gray-800 rounded-lg p-5 mb-4">
                <h2 class="text-lg font-semibold mb-3">
                    <i class="fa-solid fa-sliders mr-2 text-gray-400"></i>Parameters
                </h2>
                <div id="params-container" class="flex flex-col gap-2 mb-3">
                    <!-- Dynamic rows inserted here -->
                </div>
                <div class="flex gap-2">
                    <button onclick="resetToDefaults()" class="text-sm bg-gray-700 hover:bg-gray-600 px-3 py-1.5 rounded">
                        <i class="fa-solid fa-rotate-left mr-1"></i> Reset
                    </button>
                </div>
            </div>

            <!-- Command Preview -->
            <div class="bg-gray-800 rounded-lg p-5 mb-4">
                <h2 class="text-sm font-semibold text-gray-400 mb-2">Command Preview</h2>
                <div id="command-preview" class="font-mono text-sm text-green-400 bg-gray-950 rounded p-3 break-all">
                    llama-bench ...
                </div>
            </div>

            <!-- Run Button -->
            <div class="flex gap-3">
                <button id="run-btn" onclick="runBenchmark()" class="bg-green-600 hover:bg-green-700 px-5 py-2.5 rounded font-semibold text-sm">
                    <i class="fa-solid fa-play mr-1"></i> Run Benchmark
                </button>
            </div>
        </div>

        <!-- Right column: Parameter Reference -->
        <div class="lg:w-80 xl:w-96 flex-shrink-0">
            <div class="bg-gray-800 rounded-lg p-4 lg:sticky lg:top-4">
                <div class="flex items-center justify-between mb-3">
                    <h2 class="text-sm font-semibold text-gray-300">
                        <i class="fa-solid fa-book mr-1.5 text-gray-400"></i>Parameter Reference
                    </h2>
                    <a href="https://github.com/ggml-org/llama.cpp/blob/master/tools/llama-bench/README.md"
                       target="_blank" class="text-gray-500 hover:text-gray-300 text-xs" title="llama-bench docs">
                        <i class="fa-solid fa-arrow-up-right-from-square"></i>
                    </a>
                </div>
                <div id="param-ref-body">
                    <div class="relative mb-3">
                        <i class="fa-solid fa-magnifying-glass absolute left-2.5 top-2 text-gray-500 text-xs"></i>
                        <input type="text" id="param-search" placeholder="Search flags..."
                            oninput="filterParamRef()"
                            class="w-full bg-gray-700 border border-gray-600 rounded pl-7 pr-3 py-1.5 text-xs font-mono focus:outline-none focus:border-blue-500 placeholder-gray-500">
                    </div>
                    <div class="flex gap-3 text-[10px] text-gray-500 mb-2 px-1">
                        <span><span class="inline-block w-1.5 h-1.5 rounded-full bg-orange-400 mr-1"></span>Benchmark-only (not applied to service)</span>
                        <span><span class="inline-block w-1.5 h-1.5 rounded-full bg-yellow-400 mr-1"></span>Serve param</span>
                    </div>
                    <div id="param-ref-list" class="overflow-y-auto space-y-0.5 text-xs">
                        <!-- Populated by JS -->
                    </div>
                    <div id="param-ref-empty" class="text-gray-500 text-xs py-4 text-center hidden">
                        No matching parameters.
                    </div>
                </div>
            </div>
        </div>

    </div>

    <!-- Live Output (full width, collapsible) -->
    <div class="bg-gray-800 rounded-lg p-5 mb-6">
        <div class="flex items-center justify-between cursor-pointer select-none" onclick="toggleLiveOutput()">
            <h2 class="text-lg font-semibold">
                <i id="live-output-chevron" class="fa-solid fa-chevron-down mr-1.5 text-gray-500 text-xs transition-transform rotate-[-90deg]"></i>
                <i class="fa-solid fa-terminal mr-2 text-gray-400"></i>Live Output
            </h2>
            <span id="run-status-badge" class="px-2 py-0.5 rounded text-xs font-semibold bg-gray-700 text-gray-400">
                Idle
            </span>
        </div>
        <div id="live-output-wrapper" class="hidden mt-3">
            <div id="live-output" class="terminal-output bg-gray-950 rounded p-4 h-64 overflow-y-auto text-gray-400">
                Waiting for benchmark run...
            </div>
        </div>
    </div>

    <!-- History (full width) -->
    <div class="bg-gray-800 rounded-lg p-5">
        <h2 class="text-lg font-semibold mb-3">
            <i class="fa-solid fa-clock-rotate-left mr-2 text-gray-400"></i>History
        </h2>
        <div class="overflow-x-auto">
            <table class="w-full text-sm">
                <thead>
                    <tr class="text-gray-400 text-left border-b border-gray-700">
                        <th class="pb-2 pr-3">Date</th>
                        <th class="pb-2 pr-3">PP t/s</th>
                        <th class="pb-2 pr-3">TG t/s</th>
                        <th class="pb-2 pr-3">Key Params</th>
                        <th class="pb-2 pr-3">Status</th>
                        <th class="pb-2">Actions</th>
                    </tr>
                </thead>
                <tbody id="history-body">
                    <!-- Dynamic rows -->
                </tbody>
            </table>
        </div>
        <p id="history-empty" class="text-gray-500 text-sm mt-3 hidden">No benchmark history yet.</p>
    </div>

</div>

<script>
// ── State ──────────────────────────────────────────────
const urlParams = new URLSearchParams(window.location.search);
const serviceName = urlParams.get('service') || 'unknown-service';
let modelPath = '';
let serviceDefaults = {};

let isRunning = false;
let currentRunId = null;
let pollInterval = null;
const BENCHMARK_ONLY_FLAGS = new Set(['-m', '-p', '-n', '-r', '-o', '-pg', '-d', '-oe', '-v', '--delay', '--list-devices']);
const AUTO_ADDED_FLAGS = new Set(['-m', '-o']);
const SAFE_DEFAULTS = { '-p': '512', '-n': '128', '-r': '3' };

let historyData = [];

// ── Auth / API ─────────────────────────────────────────
const API_BASE = window.location.origin;

function getToken() {
    return localStorage.getItem('dashboard_token');
}

async function fetchAPI(endpoint, options = {}) {
    const token = getToken();
    if (!token) {
        showToast('Not authenticated. Please log in from the dashboard first.', 'error');
        throw new Error('Not authenticated');
    }
    const response = await fetch(`${API_BASE}${endpoint}`, {
        ...options,
        headers: {
            'Authorization': `Bearer ${token}`,
            'Content-Type': 'application/json',
            ...options.headers,
        },
    });
    if (response.status === 401) {
        showToast('Authentication expired. Please log in from the dashboard.', 'error');
        throw new Error('Auth expired');
    }
    return response;
}

// ── Init ───────────────────────────────────────────────
document.getElementById('service-name').textContent = serviceName;

async function initPage() {
    try {
        // Load service info
        const svcResp = await fetchAPI(`/api/services/${serviceName}`);
        if (svcResp.ok) {
            const svcData = await svcResp.json();
            const config = svcData.config || {};
            modelPath = config.model_path || '';
            document.getElementById('model-path').textContent = modelPath || 'Unknown';
        }

        // Load service status
        try {
            const statusResp = await fetchAPI('/api/services');
            if (statusResp.ok) {
                const statusData = await statusResp.json();
                const svc = (statusData.services || []).find(s => s.name === serviceName);
                if (svc) {
                    const badge = document.getElementById('service-status-badge');
                    if (svc.status === 'running') {
                        badge.innerHTML = '<span class="text-green-400">&#9679;</span> Running';
                        badge.className = 'px-2 py-0.5 rounded text-xs font-semibold bg-green-900 text-green-300';
                    } else {
                        badge.innerHTML = '<span class="text-gray-400">&#9679;</span> Stopped';
                        badge.className = 'px-2 py-0.5 rounded text-xs font-semibold bg-gray-700 text-gray-400';
                    }
                }
            }
        } catch (e) { /* status fetch is non-critical */ }

        // Load params: most recent run first, then safe defaults
        const histResp = await fetchAPI(`/api/benchmarks?service_name=${encodeURIComponent(serviceName)}&limit=1`);
        if (histResp.ok) {
            const histData = await histResp.json();
            if (histData.runs && histData.runs.length > 0) {
                loadParams(histData.runs[0].params || {});
            } else {
                loadParams(SAFE_DEFAULTS);
            }
        } else {
            loadParams(SAFE_DEFAULTS);
        }

        // Load full history
        await refreshHistory();
    } catch (e) {
        console.error('Init error:', e);
    }

    renderParamRef();
}

async function loadServiceDefaults() {
    try {
        const resp = await fetchAPI(`/api/benchmarks/service-defaults/${encodeURIComponent(serviceName)}`);
        if (resp.ok) {
            const data = await resp.json();
            serviceDefaults = data.params || {};
            if (!modelPath) {
                modelPath = data.model_path || '';
                document.getElementById('model-path').textContent = modelPath || 'Unknown';
            }
            loadParams(serviceDefaults);
        }
    } catch (e) {
        console.error('Failed to load service defaults:', e);
    }
}

initPage();

// Keep param ref height synced with left column
new ResizeObserver(() => updateParamRefHeight()).observe(document.getElementById('left-column'));

// ── Parameter Reference Data ───────────────────────────
const PARAM_REFERENCE = [
    // Benchmark-only flags first
    { cat: 'Benchmark', flag: '-m', long: '--model', desc: 'Model file path (auto-added)', def: 'auto',
      tip: 'Path to the GGUF model file. <b>Auto-added</b> from your service configuration — you don\'t need to set this manually.' },
    { cat: 'Benchmark', flag: '-o', long: '--output', desc: 'Output format (auto-added as json)', def: 'json',
      tip: 'Sets the output format for benchmark results. <b>Auto-added as json</b> so the dashboard can parse the results. You don\'t need to set this manually.' },
    { cat: 'Benchmark', flag: '-p', long: '--n-prompt', desc: 'Number of prompt tokens to process', def: '512',
      tip: 'Sets the number of tokens to process in the <b>prompt phase</b> (default: 512). This measures how quickly your system can ingest input before generation begins. Increase to test performance with larger prompts or longer context windows.' },
    { cat: 'Benchmark', flag: '-n', long: '--n-gen', desc: 'Number of tokens to generate', def: '128',
      tip: 'Specifies how many tokens to <b>generate</b> during the text generation phase (default: 128). This tests sequential token production speed, which determines response time. Higher values show sustained performance over longer outputs.' },
    { cat: 'Benchmark', flag: '-r', long: '--repetitions', desc: 'Times to repeat each test', def: '5',
      tip: 'Number of times to <b>repeat each test</b> (default: 5). Multiple runs provide statistical averaging to account for variance from thermal throttling, caching, or system load. Increase for more reliable comparisons.' },
    { cat: 'Benchmark', flag: '-pg', long: '', desc: 'Combined prompt+generation (pp,tg)', def: '',
      tip: 'Runs <b>prompt processing + text generation</b> in a single pass (format: <code>-pg 1024,256</code> for 1024 prompt + 256 generated tokens). The most realistic benchmark since it measures end-to-end inference like actual usage, rather than testing PP and TG separately.' },
    { cat: 'Benchmark', flag: '-d', long: '--n-depth', desc: 'Context depth for KV cache prefill', def: '0',
      tip: 'Sets how many tokens are already in the KV cache before the test runs. For example, <b>-d 4096</b> fills the cache with 4096 tokens first, then measures PP/TG speed. This lets you benchmark performance with a long conversation history, since attention slows down as context grows. Default is 0 (empty cache).' },
    { cat: 'Benchmark', flag: '-oe', long: '--output-err', desc: 'Stderr output format', def: 'none',
      tip: 'Directs benchmark output to <b>stderr</b> in specified format (<code>csv|json|jsonl|md|sql</code>). Use to separate diagnostic data from main results when piping stdout to files or databases.' },
    { cat: 'Benchmark', flag: '-v', long: '--verbose', desc: 'Verbose output', def: 'off',
      tip: 'Enables <b>detailed diagnostic logging</b> during test execution, showing model loading details, device configuration, and per-iteration metrics. Enable when troubleshooting performance issues or verifying test parameters.' },
{ cat: 'Benchmark', flag: '', long: '--delay', desc: 'Delay in seconds between tests', def: '0',
      tip: 'Introduces a <b>pause in seconds</b> between successive tests (default: 0). Allows GPU temperature to stabilize and caches to clear between runs. Add delay when thermal throttling might skew results.' },
    { cat: 'Benchmark', flag: '', long: '--list-devices', desc: 'List available devices and exit', def: '',
      tip: 'Displays all available <b>compute devices</b> (CPUs, GPUs, accelerators) compatible with your build, then exits. Use to verify hardware detection before configuring device-specific tests.' },

    { cat: 'Batching', flag: '-b', long: '--batch-size', desc: 'Logical batch size for prompt processing', def: '2048',
      tip: '<b>Logical batch size</b> for prompt processing (default: 2048). Controls how many tokens are processed per iteration at the application level. Larger values speed up prompt processing but require more VRAM for the logits buffer. All prompt tokens are still evaluated — they\'re just chunked into groups of this size.' },
    { cat: 'Batching', flag: '-ub', long: '--ubatch-size', desc: 'Physical micro-batch size', def: '512',
      tip: '<b>Physical micro-batch size</b> at the hardware level (default: 512). When <code>batch > ubatch</code>, processing is pipelined (e.g., batch=2048 with ubatch=512 = 4-stage pipeline). Lower values reduce VRAM usage during prompt processing. Must satisfy: <code>batch_size >= ubatch_size</code>.' },

    { cat: 'GPU', flag: '-ngl', long: '--gpu-layers', desc: 'Number of layers to offload to GPU', def: '99',
      tip: 'Controls how many model layers are stored in VRAM. Use a specific number, <code>auto</code>, or <code>-1</code>/all to offload everything. <b>Higher values = faster inference but more VRAM.</b> Start with <code>auto</code> and adjust based on available memory.' },
    { cat: 'GPU', flag: '-sm', long: '--split-mode', desc: 'Multi-GPU split mode (none|layer|row)', def: 'layer',
      tip: 'Determines how models distribute across multiple GPUs. <code>none</code> = single GPU; <code>layer</code> (default) = sequential layer distribution; <code>row</code> = parallel tensor splitting where all GPUs work simultaneously per layer. <b>Use <code>row</code> for better multi-GPU utilization.</b>' },
    { cat: 'GPU', flag: '-mg', long: '--main-gpu', desc: 'Primary GPU index for computations', def: '0',
      tip: 'Specifies which GPU (by index, default: 0) handles primary processing. With <code>split-mode=none</code>, the entire model runs here. With <code>row</code> mode, this GPU manages intermediate results and KV cache. <b>Set to your fastest GPU.</b>' },
    { cat: 'GPU', flag: '-nkvo', long: '--no-kv-offload', desc: 'Disable KV cache offload to GPU (0|1)', def: '0',
      tip: 'Keeps the KV cache in system RAM instead of VRAM. By default, KV cache uses VRAM. <b>Enable if you\'re VRAM-constrained but have plenty of RAM</b> — trades GPU memory for slower CPU memory access.' },
    { cat: 'GPU', flag: '-ts', long: '--tensor-split', desc: 'Fraction of work per GPU (comma-separated)', def: '0',
      tip: 'Defines custom proportions for distributing model weights across GPUs (e.g., <code>3,1</code> = 75%/25% split). <b>Use when GPUs have different VRAM capacities</b> to allocate smaller portions to weaker GPUs and prevent bottlenecks.' },
    { cat: 'GPU', flag: '-dev', long: '--device', desc: 'Device selection', def: 'auto',
      tip: 'Specifies which compute devices to use as a comma-separated list. Set to <code>none</code> to disable offloading entirely. <b>Run with <code>--list-devices</code> first</b> to see available devices. Useful for mixed GPU/CPU setups.' },
    { cat: 'GPU', flag: '', long: '--no-op-offload', desc: 'Disable operation offloading (0|1)', def: '0',
      tip: 'Disables GPU acceleration for host tensor operations, forcing them onto CPU. <b>Enable only for debugging</b> or if you encounter GPU operation errors — it will significantly slow down inference.' },

    { cat: 'Memory', flag: '-fa', long: '--flash-attn', desc: 'Enable flash attention (0|1)', def: '0',
      tip: 'Enables flash attention, which reduces memory bandwidth and improves GPU performance through tiling and kernel fusion. <b>Enable (set to 1) when using GPU</b> for up to ~15% throughput gains and better long-context support. Required for KV cache quantization (<code>-ctk</code>/<code>-ctv</code>).' },
    { cat: 'Memory', flag: '-ctk', long: '--cache-type-k', desc: 'KV cache type for K (f16, q8_0, q4_0, etc.)', def: 'f16',
      tip: 'Data type for the <b>key</b> component of the KV cache (default: <code>f16</code>). Options: <code>f16</code>, <code>f32</code>, <code>q8_0</code>, <code>q4_0</code>. <b>Use <code>q8_0</code> to halve KV cache VRAM</b> with minimal quality loss — useful for long contexts or fitting more layers on GPU. Requires <code>-fa 1</code>.' },
    { cat: 'Memory', flag: '-ctv', long: '--cache-type-v', desc: 'KV cache type for V (f16, q8_0, q4_0, etc.)', def: 'f16',
      tip: 'Data type for the <b>value</b> component of the KV cache (default: <code>f16</code>). Options: <code>f16</code>, <code>f32</code>, <code>q8_0</code>, <code>q4_0</code>. <b>Use <code>q8_0</code> to halve KV cache VRAM</b> with minimal quality loss. Should typically match <code>-ctk</code> setting. Requires <code>-fa 1</code>.' },
    { cat: 'Memory', flag: '', long: '--mmap', desc: 'Use memory-mapped model loading (0|1)', def: '1',
      tip: 'Controls memory-mapped file loading (default: enabled). When on, the model maps directly from disk via the OS page cache, enabling <b>instant loads on subsequent runs</b>. Disable (set to 0) to force loading the full model into RAM upfront — useful if your model is larger than available RAM or you want consistent performance without page faults.' },
    { cat: 'Memory', flag: '', long: '--embeddings', desc: 'Embeddings mode (0|1)', def: '0',
      tip: 'Switches from text generation to <b>embedding generation</b> mode. Enable (set to 1) when benchmarking vector embedding performance for semantic search, similarity tasks, or RAG applications. Requires a model designed for embeddings.' },

    { cat: 'CPU', flag: '-t', long: '--threads', desc: 'Number of threads for computation', def: 'auto',
      tip: 'Number of CPU threads for computation (default: auto-detected core count). <b>Higher values improve performance on multi-core systems</b> but may cause diminishing returns beyond the optimal count. Experiment with values like 4, 8, 16, 32 to find the sweet spot for your hardware.' },
    { cat: 'CPU', flag: '-C', long: '--cpu-mask', desc: 'CPU affinity bitmask', def: '0x0',
      tip: 'CPU affinity bitmask in hex (default: <code>0x0</code> = unrestricted). <b>Restricts execution to specific CPU cores.</b> Example: <code>0xFF</code> pins to CPUs 0-7. Useful on NUMA systems or when running multiple workloads to reduce cross-socket memory access.' },
    { cat: 'CPU', flag: '', long: '--cpu-strict', desc: 'Use strict CPU thread pinning (0|1)', def: '0',
      tip: 'Enforces <b>strict thread-to-core binding</b> to reduce context switching (default: disabled). Most beneficial when combined with <code>--cpu-mask</code> for maximum performance isolation and predictability in multi-threaded environments.' },
    { cat: 'CPU', flag: '', long: '--poll', desc: 'Polling percentage for thread sync', def: '50',
      tip: 'Controls how aggressively threads <b>spin-check for new work</b> (0-100, default: 50). Higher values reduce latency but consume more CPU power. Lower values save power by using passive waiting. Tune based on your latency vs. power efficiency needs.' },
    { cat: 'CPU', flag: '', long: '--numa', desc: 'NUMA scheduling (distribute|isolate|numactl)', def: 'disabled',
      tip: 'NUMA scheduling mode: <code>distribute</code> (spread across all nodes), <code>isolate</code> (current node only), or <code>numactl</code> (use numactl CPU map). <b>Essential for multi-socket systems</b> to optimize memory access. <code>distribute</code> with memory interleave often provides the best throughput.' },
    { cat: 'CPU', flag: '-ncmoe', long: '--n-cpu-moe', desc: 'CPU layers for MoE models', def: '0',
      tip: 'Number of MoE layers to keep on CPU, counting from the <b>highest layer number</b> (default: 0). Offloads expert FFN layers to CPU to reduce VRAM usage on large MoE models. llama.cpp may still copy CPU weights to GPU for batch processing when enough tokens are available.' },

    { cat: 'Other', flag: '', long: '--prio', desc: 'Process/thread priority (0-3)', def: '0',
      tip: 'CPU scheduling priority: <code>-1</code> (low), <code>0</code> (normal), <code>1</code> (medium), <code>2</code> (high), <code>3</code> (realtime). Higher priorities allocate more CPU time to llama.cpp. Use <b>low for background benchmarking</b>, high for dedicated performance testing.' },
    { cat: 'Other', flag: '', long: '--rpc', desc: 'RPC server addresses (comma-separated)', def: '',
      tip: 'Enables distributed benchmarking across machines by specifying RPC server addresses (e.g., <code>192.168.1.10:50052,192.168.1.11:50052</code>). Model weights and KV cache are automatically distributed proportional to available memory. <b>Experimental — do not use on open networks.</b>' },
    { cat: 'Other', flag: '-ot', long: '--override-tensors', desc: 'Override tensor buffer types', def: '',
      tip: 'Fine-grained control over which device specific tensors load to, using regex patterns (e.g., <code>-ot ".*_exps.*=CPU"</code> or <code>-ot "blk.[0-5].*=CUDA0"</code>). Buffer types: <code>CPU</code>, <code>CUDA0</code>, <code>CUDA1</code>. <b>Essential for MoE models</b> to selectively offload expert layers while keeping attention on GPU.' },
];

// ── Parameter Management ───────────────────────────────
function addParamRow(flag, value, isEmpty = false) {
    const container = document.getElementById('params-container');
    const row = document.createElement('div');
    const isBench = BENCHMARK_ONLY_FLAGS.has(flag);
    row.className = `flex gap-2 items-center param-row border-l-2 rounded-r pl-1 ${isBench ? 'border-orange-500/50' : 'border-transparent'}`;
    if (isEmpty) row.dataset.empty = '1';
    row.innerHTML = `
        <input type="text" value="${escapeAttr(flag)}" placeholder="-flag"
            class="bg-gray-700 border border-gray-600 rounded px-3 py-1.5 text-sm w-28 font-mono focus:outline-none focus:border-blue-500 ${isBench ? 'text-orange-400' : ''}"
            oninput="onParamInput(this); updateParamRowStyle(this); updatePreview()">
        <input type="text" value="${escapeAttr(value)}" placeholder="value (empty = boolean flag)"
            class="bg-gray-700 border border-gray-600 rounded px-3 py-1.5 text-sm flex-1 font-mono focus:outline-none focus:border-blue-500"
            oninput="onParamInput(this); updatePreview()">
        ${isBench ? '<span class="bench-badge text-[9px] uppercase tracking-wide font-semibold bg-orange-500/15 text-orange-400 px-1.5 py-0.5 rounded whitespace-nowrap">bench</span>' : ''}
        <button onclick="removeParamRow(this)" class="text-red-400 hover:text-red-300 px-2 py-1 ${isEmpty ? 'invisible' : ''}" title="Remove">
            <i class="fa-solid fa-xmark"></i>
        </button>
    `;
    const emptyRow = container.querySelector('.param-row[data-empty="1"]');
    if (emptyRow && !isEmpty) {
        container.insertBefore(row, emptyRow);
    } else {
        container.appendChild(row);
    }
    updatePreview();
    return row;
}

function ensureEmptyRow() {
    const container = document.getElementById('params-container');
    const emptyRow = container.querySelector('.param-row[data-empty="1"]');
    if (!emptyRow) {
        addParamRow('', '', true);
    }
}

function onParamInput(input) {
    const row = input.closest('.param-row');
    if (row.dataset.empty === '1') {
        // User started typing in the empty row — promote it to a regular row
        delete row.dataset.empty;
        row.querySelector('button').classList.remove('invisible');
        ensureEmptyRow();
    }
}

function removeParamRow(btn) {
    const row = btn.closest('.param-row');
    if (row.dataset.empty === '1') return; // can't delete the empty row
    row.remove();
    updatePreview();
    ensureEmptyRow();
}

function updateParamRowStyle(input) {
    const row = input.closest('.param-row');
    const flag = input.value.trim();
    const isBench = BENCHMARK_ONLY_FLAGS.has(flag);

    // Update row border
    row.classList.toggle('border-orange-500/50', isBench);
    row.classList.toggle('border-transparent', !isBench);

    // Update flag input color
    input.classList.toggle('text-orange-400', isBench);

    // Toggle bench badge
    const existingBadge = row.querySelector('.bench-badge');
    if (isBench && !existingBadge) {
        const badge = document.createElement('span');
        badge.className = 'bench-badge text-[9px] uppercase tracking-wide font-semibold bg-orange-500/15 text-orange-400 px-1.5 py-0.5 rounded whitespace-nowrap';
        badge.textContent = 'bench';
        row.querySelector('button').insertAdjacentElement('beforebegin', badge);
    } else if (!isBench && existingBadge) {
        existingBadge.remove();
    }
}

function getParams() {
    const rows = document.querySelectorAll('.param-row:not([data-empty="1"])');
    const params = {};
    rows.forEach(row => {
        const inputs = row.querySelectorAll('input');
        const flag = inputs[0].value.trim();
        const value = inputs[1].value.trim();
        if (flag) {
            params[flag] = value;
        }
    });
    return params;
}

function getParamsArray() {
    const rows = document.querySelectorAll('.param-row:not([data-empty="1"])');
    const params = [];
    rows.forEach(row => {
        const inputs = row.querySelectorAll('input');
        const flag = inputs[0].value.trim();
        const value = inputs[1].value.trim();
        if (flag) {
            params.push({ flag, value });
        }
    });
    return params;
}

function resetToDefaults() {
    loadParams(SAFE_DEFAULTS);
    showToast('Parameters reset to defaults', 'info');
}

function loadParams(params) {
    document.getElementById('params-container').innerHTML = '';
    // Benchmark-only flags first, then the rest
    const entries = Object.entries(params);
    const bench = entries.filter(([flag]) => BENCHMARK_ONLY_FLAGS.has(flag));
    const rest = entries.filter(([flag]) => !BENCHMARK_ONLY_FLAGS.has(flag));
    bench.concat(rest).forEach(([flag, value]) => addParamRow(flag, value));
    ensureEmptyRow();
}

// ── Command Preview ────────────────────────────────────
function updatePreview() {
    const params = getParamsArray();
    let cmd = `llama-bench -m ${modelPath} -o json`;
    params.forEach(p => {
        cmd += ` ${p.flag}`;
        if (p.value) cmd += ` ${p.value}`;
    });
    document.getElementById('command-preview').textContent = cmd;
}

// ── Run Benchmark ──────────────────────────────────────
async function runBenchmark() {
    if (isRunning) return;

    const params = getParams();
    const runBtn = document.getElementById('run-btn');
    const output = document.getElementById('live-output');
    const badge = document.getElementById('run-status-badge');

    runBtn.disabled = true;
    runBtn.innerHTML = '<i class="fa-solid fa-spinner fa-spin mr-1"></i> Starting...';
    runBtn.className = 'bg-gray-600 px-5 py-2.5 rounded font-semibold text-sm cursor-not-allowed';

    // Auto-expand live output
    document.getElementById('live-output-wrapper').classList.remove('hidden');
    document.getElementById('live-output-chevron').classList.remove('rotate-[-90deg]');

    try {
        const resp = await fetchAPI('/api/benchmarks', {
            method: 'POST',
            body: JSON.stringify({ service_name: serviceName, params }),
        });

        const data = await resp.json();

        if (!resp.ok) {
            const errMsg = data.error?.message || data.error || 'Failed to start benchmark';
            showToast(errMsg, 'error');
            resetRunButton();
            return;
        }

        currentRunId = data.id;
        isRunning = true;

        badge.textContent = 'Running';
        badge.className = 'px-2 py-0.5 rounded text-xs font-semibold bg-yellow-900 text-yellow-300';
        runBtn.innerHTML = '<i class="fa-solid fa-spinner fa-spin mr-1"></i> Running...';
        output.textContent = `Benchmark started (${currentRunId}).\nWaiting for results...\n`;
        output.className = 'terminal-output bg-gray-950 rounded p-4 h-64 overflow-y-auto text-green-400';

        showToast('Benchmark started', 'info');
        startPolling(currentRunId);
    } catch (e) {
        showToast('Failed to start benchmark: ' + e.message, 'error');
        resetRunButton();
    }
}

function startPolling(runId) {
    if (pollInterval) clearInterval(pollInterval);
    pollInterval = setInterval(() => pollRunStatus(runId), 2000);
}

function stopPolling() {
    if (pollInterval) {
        clearInterval(pollInterval);
        pollInterval = null;
    }
}

async function pollRunStatus(runId) {
    try {
        const resp = await fetchAPI(`/api/benchmarks/${runId}`);
        if (!resp.ok) return;

        const run = await resp.json();
        const output = document.getElementById('live-output');
        const badge = document.getElementById('run-status-badge');

        if (run.status === 'running') {
            badge.textContent = 'Running';
            badge.className = 'px-2 py-0.5 rounded text-xs font-semibold bg-yellow-900 text-yellow-300';
        } else if (run.status === 'completed') {
            stopPolling();
            isRunning = false;
            currentRunId = null;

            let resultText = `Benchmark completed.\n`;
            if (run.pp_avg_ts != null) resultText += `\nPrompt Processing: ${run.pp_avg_ts.toFixed(2)} t/s`;
            if (run.pp_stddev_ts != null) resultText += ` (stddev: ${run.pp_stddev_ts.toFixed(2)})`;
            if (run.tg_avg_ts != null) resultText += `\nText Generation:   ${run.tg_avg_ts.toFixed(2)} t/s`;
            if (run.tg_stddev_ts != null) resultText += ` (stddev: ${run.tg_stddev_ts.toFixed(2)})`;
            if (run.build_commit) resultText += `\n\nbuild: ${run.build_commit}`;
            if (run.gpu_info) resultText += `\ngpu:   ${run.gpu_info}`;
            if (run.raw_output) {
                resultText += `\n\n--- Raw Output ---\n${run.raw_output}`;
            }

            output.textContent = resultText;
            badge.textContent = 'Completed';
            badge.className = 'px-2 py-0.5 rounded text-xs font-semibold bg-green-900 text-green-300';
            resetRunButton();
            showToast('Benchmark completed', 'success');
            await refreshHistory();
        } else if (run.status === 'failed' || run.status === 'cancelled') {
            stopPolling();
            isRunning = false;
            currentRunId = null;

            output.textContent = `Benchmark ${run.status}.\n\n${run.error_message || ''}`;
            output.className = 'terminal-output bg-gray-950 rounded p-4 h-64 overflow-y-auto text-red-400';
            badge.textContent = run.status === 'failed' ? 'Failed' : 'Cancelled';
            badge.className = 'px-2 py-0.5 rounded text-xs font-semibold bg-red-900 text-red-300';
            resetRunButton();
            showToast(`Benchmark ${run.status}`, 'error');
            await refreshHistory();
        }
    } catch (e) {
        console.error('Poll error:', e);
    }
}

function resetRunButton() {
    const runBtn = document.getElementById('run-btn');
    runBtn.disabled = false;
    runBtn.innerHTML = '<i class="fa-solid fa-play mr-1"></i> Run Benchmark';
    runBtn.className = 'bg-green-600 hover:bg-green-700 px-5 py-2.5 rounded font-semibold text-sm';
}

// ── History Table ──────────────────────────────────────
async function refreshHistory() {
    try {
        const resp = await fetchAPI(`/api/benchmarks?service_name=${encodeURIComponent(serviceName)}&limit=50`);
        if (resp.ok) {
            const data = await resp.json();
            historyData = (data.runs || []).map(r => ({
                id: r.id,
                date: r.created_at ? r.created_at.replace('T', ' ').substring(0, 19) : '',
                pp_ts: r.pp_avg_ts,
                tg_ts: r.tg_avg_ts,
                params: r.params || {},
                status: r.status,
            }));
            renderHistory();
        }
    } catch (e) {
        console.error('Failed to refresh history:', e);
    }
}

function renderHistory() {
    const tbody = document.getElementById('history-body');
    const empty = document.getElementById('history-empty');

    if (historyData.length === 0) {
        tbody.innerHTML = '';
        empty.classList.remove('hidden');
        return;
    }
    empty.classList.add('hidden');

    tbody.innerHTML = historyData.map(row => {
        const statusIcons = {
            completed: '<span class="text-green-400"><i class="fa-solid fa-check"></i> Completed</span>',
            failed: '<span class="text-red-400"><i class="fa-solid fa-xmark"></i> Failed</span>',
            running: '<span class="text-yellow-400"><i class="fa-solid fa-spinner fa-spin"></i> Running</span>',
            pending: '<span class="text-gray-400"><i class="fa-solid fa-clock"></i> Pending</span>',
            cancelled: '<span class="text-gray-400"><i class="fa-solid fa-ban"></i> Cancelled</span>',
        };
        const statusBadge = statusIcons[row.status] || `<span class="text-gray-400">${escapeHtml(row.status)}</span>`;

        const allParams = Object.entries(row.params || {}).map(([flag, val]) =>
            val ? `${flag} ${val}` : flag
        ).join('  ');

        return `
            <tr class="border-b border-gray-700/50 hover:bg-gray-700/30">
                <td class="py-2.5 pr-3 text-gray-300 text-xs whitespace-nowrap">${escapeHtml(row.date)}</td>
                <td class="py-2.5 pr-3 font-mono ${row.pp_ts ? 'text-white' : 'text-gray-500'}">${row.pp_ts ? row.pp_ts.toFixed(1) : '—'}</td>
                <td class="py-2.5 pr-3 font-mono ${row.tg_ts ? 'text-white' : 'text-gray-500'}">${row.tg_ts ? row.tg_ts.toFixed(1) : '—'}</td>
                <td class="py-2.5 pr-3 text-gray-400 text-xs font-mono">${escapeHtml(allParams)}</td>
                <td class="py-2.5 pr-3 text-xs">${statusBadge}</td>
                <td class="py-2.5">
                    <div class="flex gap-1">
                        <button onclick="rerunBenchmark('${row.id}')" class="text-xs bg-gray-700 hover:bg-gray-600 px-2 py-1 rounded" title="Re-run with these params">
                            <i class="fa-solid fa-rotate-right"></i> Re-run
                        </button>
                        ${row.status === 'completed' ? `
                        <button onclick="applyToService('${row.id}')" class="text-xs bg-blue-700 hover:bg-blue-600 px-2 py-1 rounded" title="Apply config to service">
                            <i class="fa-solid fa-upload"></i> Apply
                        </button>` : ''}
                        <button onclick="deleteRun('${row.id}')" class="text-xs bg-red-700 hover:bg-red-600 px-2 py-1 rounded" title="Delete">
                            <i class="fa-solid fa-trash"></i>
                        </button>
                    </div>
                </td>
            </tr>
        `;
    }).join('');
}

function rerunBenchmark(id) {
    const row = historyData.find(r => r.id === id);
    if (!row) return;
    loadParams(row.params);
    window.scrollTo({ top: 0, behavior: 'smooth' });
    showToast('Parameters loaded from history run', 'info');
}

async function applyToService(id) {
    const row = historyData.find(r => r.id === id);
    if (!row) return;

    const DENYLIST = ['-p', '-n', '-r', '-o', '-m'];
    const applicable = {};
    const skipped = [];
    Object.entries(row.params).forEach(([flag, value]) => {
        if (DENYLIST.includes(flag)) skipped.push(flag);
        else applicable[flag] = value;
    });

    if (Object.keys(applicable).length === 0) {
        showToast('No applicable parameters to apply (all are benchmark-only flags)', 'warning');
        return;
    }

    const appliedStr = Object.entries(applicable)
        .map(([k, v]) => v ? `${k} ${v}` : k)
        .join(', ');

    if (!confirm(`Apply to ${serviceName}?\n\nParams: ${appliedStr}\nSkipped: ${skipped.join(', ')}\n\nService must be restarted for changes to take effect.`)) {
        return;
    }

    try {
        const resp = await fetchAPI(`/api/benchmarks/${id}/apply`, { method: 'PUT' });
        const data = await resp.json();
        if (resp.ok) {
            showToast(data.message || 'Configuration applied', 'success');
        } else {
            showToast(data.error?.message || 'Failed to apply', 'error');
        }
    } catch (e) {
        showToast('Failed to apply: ' + e.message, 'error');
    }
}

async function deleteRun(id) {
    try {
        const resp = await fetchAPI(`/api/benchmarks/${id}`, { method: 'DELETE' });
        if (resp.ok) {
            showToast('Benchmark run deleted', 'info');
            await refreshHistory();
        } else {
            const data = await resp.json();
            showToast(data.error?.message || 'Failed to delete', 'error');
        }
    } catch (e) {
        showToast('Failed to delete: ' + e.message, 'error');
    }
}

// ── Toast Notifications ────────────────────────────────
function showToast(message, type = 'info') {
    const container = document.getElementById('toast-container');
    const colors = {
        success: 'bg-green-800 border-green-600',
        info: 'bg-blue-800 border-blue-600',
        warning: 'bg-yellow-800 border-yellow-600',
        error: 'bg-red-800 border-red-600',
    };
    const toast = document.createElement('div');
    toast.className = `toast ${colors[type] || colors.info} border rounded px-4 py-2 text-sm max-w-sm shadow-lg`;
    toast.textContent = message;
    container.appendChild(toast);
    setTimeout(() => toast.remove(), 3000);
}

// ── Utilities ──────────────────────────────────────────
function sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
}

function escapeAttr(str) {
    return str.replace(/&/g, '&amp;').replace(/"/g, '&quot;').replace(/</g, '&lt;').replace(/>/g, '&gt;');
}

function escapeHtml(str) {
    return str.replace(/&/g, '&amp;').replace(/</g, '&lt;').replace(/>/g, '&gt;');
}

// ── Parameter Reference Panel ──────────────────────────

function toggleLiveOutput() {
    const wrapper = document.getElementById('live-output-wrapper');
    const chevron = document.getElementById('live-output-chevron');
    wrapper.classList.toggle('hidden');
    chevron.classList.toggle('rotate-[-90deg]');
}

function toggleParamRef() {
    const body = document.getElementById('param-ref-body');
    const chevron = document.getElementById('param-ref-chevron');
    body.classList.toggle('hidden');
    chevron.classList.toggle('rotate-[-90deg]');
    updateParamRefHeight();
}

function updateParamRefHeight() {
    const list = document.getElementById('param-ref-list');
    const body = document.getElementById('param-ref-body');
    if (!body || body.classList.contains('hidden')) return;

    const leftCol = document.getElementById('left-column');
    const refPanel = body.closest('.bg-gray-800');
    if (!leftCol || !refPanel) return;

    // Measure left column content height (not stretched flex height)
    let leftContentHeight = 0;
    for (const child of leftCol.children) {
        leftContentHeight += child.offsetHeight + 16; // mb-4 gap
    }
    leftContentHeight -= 16; // no gap after last child

    // Chrome = header + search + legend (everything in the ref panel except the list)
    list.style.maxHeight = 'none';
    const chrome = refPanel.offsetHeight - list.offsetHeight;
    const maxList = leftContentHeight - chrome;
    list.style.maxHeight = Math.max(120, maxList) + 'px';
}

function renderParamRef(filter = '') {
    const list = document.getElementById('param-ref-list');
    const empty = document.getElementById('param-ref-empty');
    const q = filter.toLowerCase();

    let html = '';
    let currentCat = '';
    let hasResults = false;

    PARAM_REFERENCE.forEach(p => {
        const flagText = p.flag || p.long;
        const searchable = `${p.flag} ${p.long} ${p.desc} ${p.cat}`.toLowerCase();
        if (q && !searchable.includes(q)) return;

        hasResults = true;

        if (p.cat !== currentCat) {
            currentCat = p.cat;
            html += `<div class="text-gray-500 uppercase tracking-wider text-[10px] font-semibold mt-2.5 mb-1 px-1">${escapeHtml(currentCat)}</div>`;
        }

        const isBenchOnly = BENCHMARK_ONLY_FLAGS.has(p.flag) || BENCHMARK_ONLY_FLAGS.has(p.long);
        const isAutoAdded = AUTO_ADDED_FLAGS.has(p.flag) || AUTO_ADDED_FLAGS.has(p.long);
        const flagColor = isBenchOnly ? 'text-orange-400' : 'text-yellow-400';
        const rowBorder = isBenchOnly ? 'border-l-2 border-orange-500/40' : 'border-l-2 border-transparent';
        const benchBadge = isBenchOnly ? ' <span class="text-[9px] uppercase tracking-wide font-semibold bg-orange-500/15 text-orange-400 px-1 py-0.5 rounded">' + (isAutoAdded ? 'auto' : 'bench') + '</span>' : '';

        const primaryFlag = escapeHtml(p.flag || p.long);
        const secondaryFlag = p.flag && p.long ? ` <span class="text-gray-600">${escapeHtml(p.long)}</span>` : '';
        const defBadge = p.def ? `<span class="text-gray-600 ml-auto pl-2 whitespace-nowrap">${escapeHtml(p.def)}</span>` : '';

        const clickable = !isAutoAdded;
        const tooltip = p.tip ? `<div class="param-tooltip">${p.tip}</div>` : '';
        html += `
            <div class="param-ref-row group rounded-r px-2 py-1.5 relative ${clickable ? 'hover:bg-gray-700/50 cursor-pointer' : 'opacity-60'} transition-colors ${rowBorder}"
                 ${clickable ? `onclick="useRefParam('${escapeAttr(p.flag || p.long)}', '${escapeAttr(p.def)}')"` : ''}
                 ${!p.tip ? `title="${isAutoAdded ? 'Auto-added, cannot be modified' : (isBenchOnly ? 'Benchmark-only — not applied to service config. ' : '') + 'Click to add ' + escapeAttr(flagText) + ' to parameters'}"` : ''}>
                <div class="flex items-center gap-1">
                    <span class="${flagColor} font-mono font-semibold">${primaryFlag}</span>${secondaryFlag}${benchBadge}${defBadge}
                </div>
                <div class="text-gray-400 leading-snug mt-0.5">${escapeHtml(p.desc)}</div>
                ${tooltip}
            </div>`;
    });

    list.innerHTML = html;
    empty.classList.toggle('hidden', hasResults);
}

function filterParamRef() {
    const q = document.getElementById('param-search').value.trim();
    renderParamRef(q);
}

function useRefParam(flag, defaultValue) {
    // Check if this flag already exists in the param rows
    const rows = document.querySelectorAll('.param-row');
    for (const row of rows) {
        const flagInput = row.querySelector('input');
        if (flagInput && flagInput.value.trim() === flag) {
            flagInput.focus();
            showToast(`${flag} is already in your parameters`, 'info');
            return;
        }
    }
    addParamRow(flag, defaultValue);
    showToast(`Added ${flag}`, 'success');
}
</script>

</body>
</html>
